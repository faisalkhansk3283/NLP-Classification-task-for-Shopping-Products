{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2306a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e205bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juver\\AppData\\Local\\Temp\\ipykernel_8120\\3314891050.py:8: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, tmp_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = 'C:/Users/juver/Downloads/glove.6B/glove.6B.100d.txt'  # Update with your GloVe file path\n",
    "tmp_file = 'C:/Users/juver/Downloads/glove.6B/glove.6B.100d.word2vec'\n",
    "\n",
    "# Convert GloVe format to Word2Vec format\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "# Load GloVe word vectors in Word2Vec format\n",
    "glove_model = KeyedVectors.load_word2vec_format(tmp_file, binary=False)\n",
    "# Load GloVe word vectors\n",
    "#glove_model = KeyedVectors.load_word2vec_format('C:/Users/juver/Downloads/glove.6B/glove.6B.100d.txt', binary=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969f2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Product Data' is the column containing your text data\n",
    "df_total = pd.read_csv(\"ecommerceDataset.csv\")\n",
    "df_total[\"Label\"] = df_total[\"Household\"]\n",
    "df_total[\"Product Data\"] = df_total[\"Paper Plane Design Framed Wall Hanging Motivational Office Decor Art Prints (8.7 X 8.7 inch) - Set of 4 Painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it. This is an special series of paintings which makes your wall very beautiful and gives a royal touch. This painting is ready to hang, you would be proud to possess this unique painting that is a niche apart. We use only the most modern and efficient printing technology on our prints, with only the and inks and precision epson, roland and hp printers. This innovative hd printing technique results in durable and spectacular looking prints of the highest that last a lifetime. We print solely with top-notch 100% inks, to achieve brilliant and true colours. Due to their high level of uv resistance, our prints retain their beautiful colours for many years. Add colour and style to your living space with this digitally printed painting. Some are for pleasure and some for eternal bliss.so bring home this elegant print that is lushed with rich colors that makes it nothing but sheer elegance to be to your friends and family.it would be treasured forever by whoever your lucky recipient is. Liven up your place with these intriguing paintings that are high definition hd graphic digital prints for home, office or any room.\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df33f5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\juver\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6daf559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "_, df = train_test_split(df_total, test_size=0.02, random_state=42)\n",
    "\n",
    "# Tokenize and preprocess\n",
    "tokenized_paragraphs = [word_tokenize(doc.lower()) for doc in df['Product Data'].astype(str).tolist()]\n",
    "\n",
    "# Function to generate GloVe embeddings for a document\n",
    "def generate_glove_embeddings(document):\n",
    "    embeddings = [glove_model[word] for word in document if word in glove_model]\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b06e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GloVe embeddings for each document\n",
    "glove_embeddings = [generate_glove_embeddings(doc) for doc in tokenized_paragraphs]\n",
    "df['GloVe Embeddings'] = glove_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "566ec80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with the rest of your code for model training and evaluation\n",
    "import numpy as np\n",
    "# Function to calculate the mean of embeddings\n",
    "'''\n",
    "def calculate_mean(lst):\n",
    "    return np.mean(lst)\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mean(lst):\n",
    "    numeric_values = [value for value in lst if isinstance(value, (int, float))]\n",
    "    return np.mean(numeric_values) if numeric_values else np.nan\n",
    "'''\n",
    "def calculate_mean(lst):\n",
    "    if isinstance(lst, (int, float)):\n",
    "        return lst\n",
    "    numeric_values = [value for value in lst if isinstance(value, (int, float))]\n",
    "    return np.mean(numeric_values) if numeric_values else np.nan\n",
    "\n",
    "\n",
    "# Function to get train/test splits\n",
    "def get_splits(embedding):\n",
    "    X = df[embedding].apply(pd.Series)\n",
    "    X = X.applymap(calculate_mean)\n",
    "    X = X.fillna(0)\n",
    "    y = df['Label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b2e56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "models = {'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          'SVM': SVC(kernel='linear'),\n",
    "          'Logistic Regression': LogisticRegression(max_iter=1000)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e9d71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_scores(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd9af9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Label trained on Random Forest model: 0.43564356435643564\n",
      "F1 Score with Label trained on Random Forest model: 0.26439057698873336\n",
      "Accuracy with Label trained on SVM model: 0.43564356435643564\n",
      "F1 Score with Label trained on SVM model: 0.26439057698873336\n",
      "Accuracy with Label trained on Logistic Regression model: 0.43564356435643564\n",
      "F1 Score with Label trained on Logistic Regression model: 0.26439057698873336\n",
      "Accuracy with Product Data trained on Random Forest model: 0.43564356435643564\n",
      "F1 Score with Product Data trained on Random Forest model: 0.26439057698873336\n",
      "Accuracy with Product Data trained on SVM model: 0.43564356435643564\n",
      "F1 Score with Product Data trained on SVM model: 0.26439057698873336\n",
      "Accuracy with Product Data trained on Logistic Regression model: 0.43564356435643564\n",
      "F1 Score with Product Data trained on Logistic Regression model: 0.26439057698873336\n",
      "Accuracy with GloVe Embeddings trained on Random Forest model: 0.43564356435643564\n",
      "F1 Score with GloVe Embeddings trained on Random Forest model: 0.26439057698873336\n",
      "Accuracy with GloVe Embeddings trained on SVM model: 0.43564356435643564\n",
      "F1 Score with GloVe Embeddings trained on SVM model: 0.26439057698873336\n",
      "Accuracy with GloVe Embeddings trained on Logistic Regression model: 0.43564356435643564\n",
      "F1 Score with GloVe Embeddings trained on Logistic Regression model: 0.26439057698873336\n"
     ]
    }
   ],
   "source": [
    "emb = df.columns[2:]\n",
    "\n",
    "for embedding in emb:\n",
    "    X_train, X_test, y_train, y_test = get_splits(embedding)\n",
    "    for model_name, model in models.items():\n",
    "        accuracy, f1 = get_scores(model, X_train, X_test, y_train, y_test)\n",
    "        print(f'Accuracy with {embedding} trained on {model_name} model: {accuracy}')\n",
    "        print(f'F1 Score with {embedding} trained on {model_name} model: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b699a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
